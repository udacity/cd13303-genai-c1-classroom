{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e672bb19",
   "metadata": {},
   "source": [
    "# Exercise: Teach an LLM to Spell with Group Relative Policy Optimization (GRPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01691a",
   "metadata": {},
   "source": [
    "Large language models (LLMs) are notoriously bad at spelling. This is partly because tokenizers break words into smaller pieces, so the model learns about sub-word units rather than whole words and their spellings.\n",
    "\n",
    "In this exercise, you'll use Group Relative Policy Optimization (GRPO) and a technique called Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA) to teach a small LLM how to spell words. This is a classic example of teaching a model a new skill that isn't well-represented in its pre-training data.\n",
    "\n",
    "## What you'll do in this notebook\n",
    "\n",
    "1.  **Setup**: Import libraries and configure the environment.\n",
    "2.  **Load the tokenizer and base model**: Use a small, instruction-tuned model as our starting point.\n",
    "3.  **Create the dataset**: Generate a simple dataset of words and their correct spellings.\n",
    "4.  **Evaluate the base model**: Test the model's spelling ability *before* fine-tuning to establish a baseline.\n",
    "5.  **Configure LoRA and train**: Attach a LoRA adapter to the model and fine-tune it on the spelling dataset.\n",
    "6.  **Evaluate the fine-tuned model**: Test the model again to see if its spelling has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04085e7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97437029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup imports\n",
    "# No changes needed in this cell\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Use GPU, MPS, or CPU, in that order of preference\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0a0d7",
   "metadata": {},
   "source": [
    "## Step 1. Load the tokenizer and base model\n",
    "\n",
    "The model `HuggingFaceTB/SmolLM2-135M-Instruct` is a small, instruction-tuned model that's suitable for this exercise. It has 135 million parameters, making it lightweight and efficient for fine-tuning. It's not the most powerful model, but it's a good choice for demonstrating the concepts of SFT and PEFT with LoRA, especially on a CPU or limited GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8028ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters (total): 134515008\n"
     ]
    }
   ],
   "source": [
    "# Student task: Load the model and tokenizer, and copy the model to the device.\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "# See: https://huggingface.co/docs/transformers/en/models\n",
    "# See: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
    "\n",
    "# Model ID for SmolLM2-135M-Instruct\n",
    "model_id = \"***********\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = \"***********\"\n",
    "\n",
    "# Load the model\n",
    "model = \"***********\"\n",
    "\n",
    "# Copy the model to the device (GPU, MPS, or CPU)\n",
    "model = \"***********\"\n",
    "\n",
    "\n",
    "# <<< START SOLUTION SECTION\n",
    "# Model ID for SmolLM2-135M-Instruct\n",
    "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    ")\n",
    "\n",
    "# Copy the model to the device (GPU, MPS, or CPU)\n",
    "model = model.to(device)\n",
    "# <<< END SOLUTION SECTION\n",
    "\n",
    "print(\"Model parameters (total):\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6665787",
   "metadata": {},
   "source": [
    "## Step 2. Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46de84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of words of different lengths\n",
    "# No changes are needed in this cell.\n",
    "\n",
    "# fmt: off\n",
    "ALL_WORDS = [\n",
    "    \"idea\", \"glow\", \"rust\", \"maze\", \"echo\", \"wisp\", \"veto\", \"lush\", \"gaze\", \"knit\", \"fume\", \"plow\",\n",
    "    \"void\", \"oath\", \"grim\", \"crisp\", \"lunar\", \"fable\", \"quest\", \"verge\", \"brawn\", \"elude\", \"aisle\",\n",
    "    \"ember\", \"crave\", \"ivory\", \"mirth\", \"knack\", \"wryly\", \"onset\", \"mosaic\", \"velvet\", \"sphinx\",\n",
    "    \"radius\", \"summit\", \"banner\", \"cipher\", \"glisten\", \"mantle\", \"scarab\", \"expose\", \"fathom\",\n",
    "    \"tavern\", \"fusion\", \"relish\", \"lantern\", \"enchant\", \"torrent\", \"capture\", \"orchard\", \"eclipse\",\n",
    "    \"frescos\", \"triumph\", \"absolve\", \"gossipy\", \"prelude\", \"whistle\", \"resolve\", \"zealous\",\n",
    "    \"mirage\", \"aperture\", \"sapphire\",\n",
    "]\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbeab6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\ntriumph\\n\\nSpelling:\\n',\n",
       " 'completion': 'T-R-I-U-M-P-H.',\n",
       " 'word': 'triumph',\n",
       " 'spelling': 'T-R-I-U-M-P-H'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student Task: Create a Hugging Face Dataset with the prompt that asks the model to spell the word\n",
    "# with hyphens between the letters.\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "\n",
    "def generate_records():\n",
    "    for word in ALL_WORDS:\n",
    "        yield {\n",
    "            # We will use the GRPOTrainer which expects to receieve formatted prompts\n",
    "            # to pass to the LLM\n",
    "            # https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
    "            # \"**********\": f\"**********\",\n",
    "            # <<< START SOLUTION SECTION\n",
    "            \"prompt\": (\n",
    "                f\"You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\n{word}\\n\\n\"\n",
    "                + \"Spelling:\\n\"\n",
    "            ),\n",
    "            # >>> END SOLUTION SECTION\n",
    "            # Before using GRPOTrainer, will run a few epochs of supervised-fine tuning (SFT)\n",
    "            # which can be useful to give an initial nudge to the model. Thus we need to provide\n",
    "            # the gold standard answer.\n",
    "            # See the documentation for more details:\n",
    "            # https://huggingface.co/docs/trl/en/sft_trainer#expected-dataset-type-and-format\n",
    "            # \"**********\": \"-\".join(word).upper() + \".\",\n",
    "            # <<< START SOLUTION SECTION\n",
    "            \"completion\": \"-\".join(word).upper() + \".\",\n",
    "            # >>> END SOLUTION SECTION\n",
    "            # GRPOTrainer does not expect a completion, but we can add extra columns to our dataset\n",
    "            # that our reward functions will use to grade the completions provided by the LLM.\n",
    "            \"word\": word,\n",
    "            \"spelling\": \"-\".join(word).upper(),\n",
    "        }\n",
    "\n",
    "\n",
    "ds = Dataset.from_generator(generate_records)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Show the first item of the train split\n",
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a9436",
   "metadata": {},
   "source": [
    "## Step 3. Evaluate the base model\n",
    "\n",
    "Before we fine-tune the model, let's see how it performs on the spelling task. We'll create a helper function to generate a spelling for a given word and compare it to the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6581c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function that will help us visualize the performance of the model\n",
    "# No changes needed in this cell\n",
    "\n",
    "\n",
    "def check_spelling(\n",
    "    model, tokenizer, prompt: str, actual_spelling: str, max_new_tokens: int = 20\n",
    ") -> (str, str):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    gen = model.generate(\n",
    "        **inputs, max_new_tokens=max_new_tokens\n",
    "    )  # No parameters = greedy search\n",
    "    output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the generated spelling from the full output string\n",
    "    proposed_spelling = output.split(\"Spelling:\\n\")[-1].strip().split(\"\\n\")[0].strip()\n",
    "\n",
    "    # strip any whitepsace from the actual spelling\n",
    "    actual_spelling = actual_spelling.strip()\n",
    "\n",
    "    print(\n",
    "        f\"Proposed: {proposed_spelling} | Actual: {actual_spelling} \"\n",
    "        f\"| Matches: {'✅' if proposed_spelling == actual_spelling else '❌'}\"\n",
    "    )\n",
    "\n",
    "    # Remove hyphens for a character-by-character comparison\n",
    "    proposed_spelling = proposed_spelling.replace(\"-\", \"\")\n",
    "    actual_spelling = actual_spelling.replace(\"-\", \"\")\n",
    "\n",
    "    # Calculate the proportion of the spelling that was correct\n",
    "    num_correct = sum(1 for a, b in zip(actual_spelling, proposed_spelling) if a == b)\n",
    "\n",
    "    return num_correct / len(actual_spelling)  # Return proportion correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7642646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: trium | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
      "Proposed: sapp | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
      "Proposed: expose | Actual: E-X-P-O-S-E | Matches: ❌\n",
      "Proposed: fres | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
      "Proposed: wisp | Actual: W-I-S-P | Matches: ❌\n",
      "Proposed: mi-er-ge | Actual: M-I-R-A-G-E | Matches: ❌\n",
      "Proposed: ivory | Actual: I-V-O-R-Y | Matches: ❌\n",
      "Proposed: onset | Actual: O-N-S-E-T | Matches: ❌\n",
      "Proposed: elude | Actual: E-L-U-D-E | Matches: ❌\n",
      "Proposed: sphinx | Actual: S-P-H-I-N-X | Matches: ❌\n",
      "Proposed: brawn | Actual: B-R-A-W-N | Matches: ❌\n",
      "Proposed: goss | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
      "Proposed: enchant | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
      "Proposed: tavern | Actual: T-A-V-E-R-N | Matches: ❌\n",
      "Proposed: whistle | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
      "Proposed: W-O-R-D | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
      "Proposed: echo | Actual: E-C-H-O | Matches: ❌\n",
      "Proposed: mirth | Actual: M-I-R-T-H | Matches: ❌\n",
      "Proposed: cris | Actual: C-R-I-S-P | Matches: ❌\n",
      "Proposed: zeal | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
      "0.0/20.0 words correct\n"
     ]
    }
   ],
   "source": [
    "# Student task: Evaluate the base model's spelling ability\n",
    "# We expect it to perform poorly, as it hasn't been trained for this task.\n",
    "\n",
    "proportion_correct = 0.0\n",
    "\n",
    "for example in ds[\"train\"].select(range(20)):\n",
    "    prompt = example[\"prompt\"]\n",
    "    spelling = example[\"spelling\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=spelling,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/20.0 words correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6563f",
   "metadata": {},
   "source": [
    "As expected, the base model is terrible at spelling. It mostly just repeats the word back. Now, let's fine-tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7ef15",
   "metadata": {},
   "source": [
    "## Step 4. Configure LoRA and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a39e8",
   "metadata": {},
   "source": [
    "Let’s attach a LoRA adapter to the base model. We use a LoRA config so only a tiny fraction of parameters are trainable. Read more here: [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b8d596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params BEFORE: 134,515,008 / 134,515,008 (100.00%)\n",
      "Trainable params AFTER: 3,686,400 / 138,201,408 (2.67%)\n"
     ]
    }
   ],
   "source": [
    "# Student task: Configure LoRA for a causal LM and wrap the model with get_peft_model\n",
    "# Complete the sections with **********\n",
    "\n",
    "# Print how many params are trainable at first\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\n",
    "    f\"Trainable params BEFORE: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
    ")\n",
    "\n",
    "# See: https://huggingface.co/docs/peft/package_reference/lora\n",
    "# lora_config = LoraConfig(\n",
    "#     r=**********,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
    "#     lora_alpha=**********,        # LoRA scaling factor.\n",
    "#     lora_dropout=**********,      # Dropout probability for LoRA layers.\n",
    "#     bias=\"none\",\n",
    "#     task_type=**********,         # Causal Language Modeling.\n",
    "# )\n",
    "# # Wrap the base model with get_peft_model\n",
    "# model = get_peft_model(**********, **********)\n",
    "\n",
    "# <<< START SOLUTION SECTION\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "# >>> END SOLUTION SECTION\n",
    "\n",
    "# Print the number of trainable parameters after applying LoRA\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\n",
    "    f\"Trainable params AFTER: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5e91b",
   "metadata": {},
   "source": [
    "Now let’s set the training arguments. We'll use `SFTConfig` from the TRL library, which is a wrapper around the standard `TrainingArguments`. We keep epochs, batch size, and sequence length modest to finish training quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9341ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baa5b7c780a4bacb12a43462fbd454b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/udacity/udacity genai nd c1 project refresh 2025/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0615, 'grad_norm': 0.28181013464927673, 'learning_rate': 0.0004058724504646834, 'epoch': 2.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c9d5ea357f4a53a7102588a4a6ec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8536208868026733, 'eval_runtime': 0.1366, 'eval_samples_per_second': 51.232, 'eval_steps_per_second': 14.638, 'eval_num_tokens': 6833.0, 'eval_mean_token_accuracy': 0.6834677457809448, 'epoch': 2.86}\n",
      "{'loss': 0.5235, 'grad_norm': 0.35914021730422974, 'learning_rate': 0.00019436976651092142, 'epoch': 5.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac4cdc4c3d4c4690e5f61ca9e507c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7460055351257324, 'eval_runtime': 0.0794, 'eval_samples_per_second': 88.106, 'eval_steps_per_second': 25.173, 'eval_num_tokens': 13603.0, 'eval_mean_token_accuracy': 0.7412634193897247, 'epoch': 5.71}\n",
      "{'loss': 0.4247, 'grad_norm': 0.27732419967651367, 'learning_rate': 2.4757783024395242e-05, 'epoch': 8.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5255f9b713634d93b7e8d5fe63067101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7350455522537231, 'eval_runtime': 0.0796, 'eval_samples_per_second': 87.914, 'eval_steps_per_second': 25.118, 'eval_num_tokens': 20407.0, 'eval_mean_token_accuracy': 0.7412634193897247, 'epoch': 8.57}\n",
      "{'train_runtime': 16.5062, 'train_samples_per_second': 33.321, 'train_steps_per_second': 4.241, 'train_loss': 0.6325836181640625, 'num_tokens': 23760.0, 'mean_token_accuracy': 0.7896737671324185, 'epoch': 10.0}\n",
      "Proposed: T-I-R-U-M-P-H. | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
      "Proposed: S-A-P-I-C-R-H. | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
      "Proposed: E-X-P-S-E-T. | Actual: E-X-P-O-S-E | Matches: ❌\n",
      "Proposed: F-S-R-E-C-O-S. | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
      "Proposed: W-I-P-S. | Actual: W-I-S-P | Matches: ❌\n",
      "Proposed: M-I-R-E-G. | Actual: M-I-R-A-G-E | Matches: ❌\n",
      "Proposed: I-V-O-R-Y. | Actual: I-V-O-R-Y | Matches: ❌\n",
      "Proposed: O-N-S-H-O-R-D. | Actual: O-N-S-E-T | Matches: ❌\n",
      "Proposed: E-L-E-U-D. | Actual: E-L-U-D-E | Matches: ❌\n",
      "Proposed: S-P-H-I-N-X. | Actual: S-P-H-I-N-X | Matches: ❌\n",
      "Proposed: B-R-A-N-Y. | Actual: B-R-A-W-N | Matches: ❌\n",
      "Proposed: G-S-O-P-I-Y. | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
      "Proposed: E-N-C-H-A-N-T. | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
      "Proposed: T-A-A-N-R. | Actual: T-A-V-E-R-N | Matches: ❌\n",
      "Proposed: W-H-I-S-E. | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
      "Proposed: C-U-P-H-E-R-T. | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
      "Proposed: E-C-H-O-R-E. | Actual: E-C-H-O | Matches: ❌\n",
      "Proposed: M-I-R-T. | Actual: M-I-R-T-H | Matches: ❌\n",
      "Proposed: C-R-I-S-P. | Actual: C-R-I-S-P | Matches: ❌\n",
      "Proposed: Z-E-A-L-O-U-S. | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
      "13.51309523809524/20.0 words correct\n"
     ]
    }
   ],
   "source": [
    "# Train the model for a few epochs using SFT before GRPO as in certain cases\n",
    "# they can work together synergystically.\n",
    "# See: https://arxiv.org/html/2507.08267v1\n",
    "# No changes needed here\n",
    "\n",
    "output_dir = \"data/model\"\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5 * 1e-4,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=[],\n",
    "    fp16=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    args=training_args,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "proportion_correct = 0.0\n",
    "\n",
    "for example in ds[\"train\"].select(range(20)):\n",
    "    prompt = example[\"prompt\"]\n",
    "    spelling = example[\"spelling\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=spelling,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/20.0 words correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d995e64",
   "metadata": {},
   "source": [
    "The number of words has slightly increased. Let's try training using GRPO now.\n",
    "\n",
    "First let's create some reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8e58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Task: Create a helper function proportion_correct that takes a word and\n",
    "# a proposed spelling from the LLM and returns a score where every matched character\n",
    "# adds +1 and every  mismatched character subtracts 1 from the reward--including the\n",
    "# hyphens.\n",
    "# TODO: Replace occurences of **********\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def proportion_correct(word, proposed_spelling):\n",
    "    correct_spelling = \"-\".join(word).upper()\n",
    "\n",
    "    score = 0.0\n",
    "\n",
    "    # Pad to the same length to handle extra characters\n",
    "    max_len = max(len(correct_spelling), len(proposed_spelling))\n",
    "    proposed_spelling_padded = proposed_spelling.ljust(max_len, \" \")\n",
    "    correct_spelling_padded = correct_spelling.ljust(max_len, \" \")\n",
    "\n",
    "    for a, b in zip(correct_spelling_padded, proposed_spelling_padded):\n",
    "        # Add 1 for matched characters, and subtract one for mismatched\n",
    "        # **********\n",
    "\n",
    "        # <<< START SOLUTION SECTION\n",
    "        if a == b:\n",
    "            score += 1\n",
    "        else:\n",
    "            score -= 1\n",
    "        # >>> END SOLUTION SECTION\n",
    "\n",
    "    return score / (\n",
    "        len(correct_spelling)\n",
    "    )  # Normalize by length of spelling, including dashes\n",
    "\n",
    "\n",
    "assert proportion_correct(\"hello\", \"H-E-L-L-O\") == 9 / 9\n",
    "assert proportion_correct(\"hello\", \"H-E-L-\") == 3 / 9\n",
    "assert proportion_correct(\"hello\", \"H-E-L-L-O!\") == 8 / 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e1457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "Completion example first line: hello -> H-E-L-L-O\n",
      "Spelling mean and std: 0.741 +/- 0.292\n"
     ]
    }
   ],
   "source": [
    "# Create a `reward_spelling` function that receives a batch of completions and the associated word values\n",
    "# No changes needed here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reward_spelling(completions, word, **kwargs):\n",
    "    \"\"\"Reward function that rewards completions with more unique letters.\"\"\"\n",
    "\n",
    "    completion_strings = [\n",
    "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
    "    ]\n",
    "    words = [w for w in word]\n",
    "\n",
    "    rewards = [proportion_correct(w, c) for w, c in zip(words, completion_strings)]\n",
    "\n",
    "    # When training, GRPO will pass multiple completions and words to this function.\n",
    "    # We print just the first one to observe what is happening under the hood.\n",
    "    print(\"=====\")\n",
    "    print(\n",
    "        \"Completion example first line:\",\n",
    "        words[0],\n",
    "        \"->\",\n",
    "        completion_strings[0].strip().split(\"\\n\")[0].strip(),\n",
    "    )\n",
    "    print(f\"Spelling mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\")\n",
    "    return rewards\n",
    "\n",
    "\n",
    "assert reward_spelling(\n",
    "    completions=[\n",
    "        \"H-E-L-L-O\",\n",
    "        \"H-E-L-\",\n",
    "        \"H-E-L-L-O!\",\n",
    "    ],\n",
    "    word=[\n",
    "        \"hello\",\n",
    "        \"hello\",\n",
    "        \"hello\",\n",
    "    ],\n",
    ") == [1, 3 / 9, 8 / 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b98d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter-dash-letter rewards mean and std: 0.333 +/- 0.471\n"
     ]
    }
   ],
   "source": [
    "# Student task: Create a reward of 1.0 for completions starting with a string\n",
    "# formatted like X-Y-Z else return 0.0\n",
    "# TODO: Replace sections marked with **********\n",
    "\n",
    "\n",
    "def reward_response_in_form_of_letter_dash_letter(completions, word, **kwargs):\n",
    "    \"\"\"Reward function that gives a bonus for completions in the form of LETTER-DASH-LETTER.\"\"\"\n",
    "    pattern = re.compile(r\"^([A-Z]-)+[A-Z]\")  # Pattern for LETTER-DASH-LETTER\n",
    "\n",
    "    words = [w for w in word]\n",
    "\n",
    "    # Normalize the completions, taking the first line and removing extra whitespace\n",
    "    completion_strings = [\n",
    "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
    "    ]\n",
    "\n",
    "    # Create a list of rewards corresponding to completions\n",
    "    # Each completion that matches the pattern should receive 1.0,\n",
    "    # else 0.0\n",
    "    # rewards = [\n",
    "    #     **********\n",
    "    # ]\n",
    "\n",
    "    # <<< START COMPLETION SECTION\n",
    "    rewards = [\n",
    "        1.0 if pattern.match(c) else 0.0 for w, c in zip(words, completion_strings)\n",
    "    ]\n",
    "    # >>> END COMPLETION SECTION\n",
    "\n",
    "    print(\n",
    "        f\"Letter-dash-letter rewards mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\"\n",
    "    )\n",
    "    return rewards\n",
    "\n",
    "\n",
    "assert reward_response_in_form_of_letter_dash_letter(\n",
    "    completions=[\n",
    "        \"H-E-L-L-O\",\n",
    "        \"hello\",\n",
    "        \"Hi!\",\n",
    "    ],\n",
    "    word=[\n",
    "        \"hello\",\n",
    "        \"hello\",\n",
    "        \"hello\",\n",
    "    ],\n",
    ") == [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a9d1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831034615dd14f06a28fbbdffb8fc009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "Completion example first line: mirth -> M-I-R-H.\n",
      "Spelling mean and std: 0.107 +/- 0.263\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-T-N-I-R.\n",
      "Spelling mean and std: 0.468 +/- 0.218\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: summit -> S-U-M-T-I-A.\n",
      "Spelling mean and std: 0.273 +/- 0.328\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-U-L-E.\n",
      "Spelling mean and std: 0.218 +/- 0.236\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.525 +/- 0.270\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0006, 'grad_norm': 0.33242887258529663, 'learning_rate': 4.996067037544542e-05, 'num_tokens': 1716.0, 'completions/mean_length': 11.9, 'completions/min_length': 9.4, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.9, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.318112450838089, 'rewards/reward_spelling/std': 0.2811168015003204, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.2931124210357665, 'reward_std': 0.3088710129261017, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.18}\n",
      "=====\n",
      "Completion example first line: resolve -> R-E-S-I-V-E-S.\n",
      "Spelling mean and std: 0.402 +/- 0.380\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: tavern -> T-A-W-A-N.\n",
      "Spelling mean and std: 0.162 +/- 0.147\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: brawn -> B-A-R-W-N.\n",
      "Spelling mean and std: 0.319 +/- 0.280\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sapphire -> S-A-P-A-I-R-H.\n",
      "Spelling mean and std: 0.204 +/- 0.231\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fathom -> F-H-I-M-E.\n",
      "Spelling mean and std: -0.106 +/- 0.582\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0168, 'grad_norm': 0.395367294549942, 'learning_rate': 4.984280524733107e-05, 'num_tokens': 3456.0, 'completions/mean_length': 12.7, 'completions/min_length': 9.8, 'completions/max_length': 15.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.7, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 15.8, 'rewards/reward_spelling/mean': 0.19630480706691741, 'rewards/reward_spelling/std': 0.3463694632053375, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.1713048219680786, 'reward_std': 0.30534379482269286, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.36}\n",
      "=====\n",
      "Completion example first line: rust -> R-U-T.\n",
      "Spelling mean and std: 0.030 +/- 0.149\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: oath -> O-A-H-O-T.\n",
      "Spelling mean and std: 0.211 +/- 0.280\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: crisp -> C-I-S-P-R-I-S-T.\n",
      "Spelling mean and std: 0.194 +/- 0.422\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: prelude -> P-R-I-L-U-L-E.\n",
      "Spelling mean and std: 0.022 +/- 0.412\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mosaic -> M-IS-A-R-U-T-E.\n",
      "Spelling mean and std: -0.099 +/- 0.494\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0164, 'grad_norm': 0.5113060474395752, 'learning_rate': 4.96467754629559e-05, 'num_tokens': 5136.0, 'completions/mean_length': 11.1, 'completions/min_length': 9.0, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.1, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.07173105105757713, 'rewards/reward_spelling/std': 0.3756489872932434, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.0717310428619384, 'reward_std': 0.35344126224517824, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.54}\n",
      "=====\n",
      "Completion example first line: glow -> G-L-O-V-L-O.\n",
      "Spelling mean and std: 0.011 +/- 0.364\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: knit -> N-I-K-T.\n",
      "Spelling mean and std: 0.063 +/- 0.342\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: verge -> V-E-R-G-I-E.\n",
      "Spelling mean and std: 0.261 +/- 0.167\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mirage -> M-I-A-R-E.\n",
      "Spelling mean and std: 0.261 +/- 0.205\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: void -> V-O-T-I-S-R-C-E.\n",
      "Spelling mean and std: 0.054 +/- 0.403\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0113, 'grad_norm': 0.5416772365570068, 'learning_rate': 4.937319780454559e-05, 'num_tokens': 6852.0, 'completions/mean_length': 12.2, 'completions/min_length': 9.0, 'completions/max_length': 17.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.2, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 17.0, 'rewards/reward_spelling/mean': 0.1300949089229107, 'rewards/reward_spelling/std': 0.31671387553215025, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.1050949096679688, 'reward_std': 0.3336391717195511, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.71}\n",
      "=====\n",
      "Completion example first line: echo -> E-C-E-H-O-R-E.\n",
      "Spelling mean and std: 0.250 +/- 0.630\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: frescos -> F-R-S-C-O-S-I-S.\n",
      "Spelling mean and std: 0.135 +/- 0.137\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: torrent -> T-U-R-A-C-T.\n",
      "Spelling mean and std: 0.163 +/- 0.224\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: relish -> R-E-L-S.\n",
      "Spelling mean and std: 0.303 +/- 0.203\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: grim -> G-R-H-R.\n",
      "Spelling mean and std: 0.155 +/- 0.133\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0073, 'grad_norm': 0.28547364473342896, 'learning_rate': 4.9022933048627496e-05, 'num_tokens': 8588.0, 'completions/mean_length': 12.3, 'completions/min_length': 9.8, 'completions/max_length': 16.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.3, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 16.2, 'rewards/reward_spelling/mean': 0.2012654036283493, 'rewards/reward_spelling/std': 0.2836012035608292, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2012654066085815, 'reward_std': 0.161235573887825, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.89}\n",
      "=====\n",
      "Completion example first line: cipher -> C-I-F-A-M.\n",
      "Spelling mean and std: 0.440 +/- 0.463\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: elude -> E-L-U-D.\n",
      "Spelling mean and std: 0.253 +/- 0.476\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: fusion -> F-U-S-R-I-A.\n",
      "Spelling mean and std: 0.125 +/- 0.163\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-S-I-N.\n",
      "Spelling mean and std: 0.514 +/- 0.315\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sphinx -> S-P-H-N-I-X.\n",
      "Spelling mean and std: 0.284 +/- 0.229\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0441, 'grad_norm': 0.29502105712890625, 'learning_rate': 4.8597083257709194e-05, 'num_tokens': 10264.0, 'completions/mean_length': 10.871428489685059, 'completions/min_length': 9.0, 'completions/max_length': 13.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 10.871428489685059, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 13.0, 'rewards/reward_spelling/mean': 0.3232240080833435, 'rewards/reward_spelling/std': 0.35195456743240355, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.2982239961624145, 'reward_std': 0.28650709688663484, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.11}\n",
      "=====\n",
      "Completion example first line: prelude -> P-R-E-L-U-N-D.\n",
      "Spelling mean and std: 0.255 +/- 0.246\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: grim -> G-R-H-O-R-I-E-N.\n",
      "Spelling mean and std: -0.126 +/- 0.319\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: brawn -> B-R-A-N-Y.\n",
      "Spelling mean and std: 0.319 +/- 0.326\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sapphire -> S-A-P-I-C-R-H-I.\n",
      "Spelling mean and std: 0.236 +/- 0.214\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.527 +/- 0.327\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0423, 'grad_norm': 0.6090482473373413, 'learning_rate': 4.8096988312782174e-05, 'num_tokens': 11996.0, 'completions/mean_length': 12.3, 'completions/min_length': 9.8, 'completions/max_length': 15.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.3, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 15.8, 'rewards/reward_spelling/mean': 0.2420873761177063, 'rewards/reward_spelling/std': 0.3060036152601242, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2420873761177063, 'reward_std': 0.2837556034326553, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.29}\n",
      "=====\n",
      "Completion example first line: velvet -> V-E-L-V-E-T.\n",
      "Spelling mean and std: 0.495 +/- 0.445\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-N-A-R-B.\n",
      "Spelling mean and std: 0.191 +/- 0.188\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-E-R-R-A-T-E.\n",
      "Spelling mean and std: 0.474 +/- 0.312\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-T-R-E.\n",
      "Spelling mean and std: 0.194 +/- 0.265\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: verge -> V-E-R-G-E.\n",
      "Spelling mean and std: 0.206 +/- 0.464\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0003, 'grad_norm': 0.2782715857028961, 'learning_rate': 4.752422169756048e-05, 'num_tokens': 13726.0, 'completions/mean_length': 12.05, 'completions/min_length': 10.2, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.05, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.3121195435523987, 'rewards/reward_spelling/std': 0.35804441571235657, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3121195793151856, 'reward_std': 0.3021123558282852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.46}\n",
      "=====\n",
      "Completion example first line: frescos -> F-S-R-O-S-C-E.\n",
      "Spelling mean and std: 0.173 +/- 0.175\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ember -> E-M-B-I-U.\n",
      "Spelling mean and std: 0.361 +/- 0.282\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fathom -> F-A-M-H-O-R-E-N.\n",
      "Spelling mean and std: 0.239 +/- 0.380\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: scarab -> S-A-R-C-A.\n",
      "Spelling mean and std: 0.294 +/- 0.262\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: void -> The word should be spelled W-O-R-T-I.\n",
      "Spelling mean and std: -0.519 +/- 1.380\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "{'loss': 0.0239, 'grad_norm': 0.6915918588638306, 'learning_rate': 4.6880585547718845e-05, 'num_tokens': 15409.0, 'completions/mean_length': 11.175, 'completions/min_length': 8.6, 'completions/max_length': 15.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.175, 'completions/min_terminated_length': 8.6, 'completions/max_terminated_length': 15.2, 'rewards/reward_spelling/mean': 0.10943502187728882, 'rewards/reward_spelling/std': 0.5300148606300354, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.0844350278377533, 'reward_std': 0.483286589384079, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.64}\n",
      "=====\n",
      "Completion example first line: elude -> E-L-U-S.\n",
      "Spelling mean and std: 0.319 +/- 0.225\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: idea -> I-D-O-C-E.\n",
      "Spelling mean and std: 0.047 +/- 0.391\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aisle -> A-S-E-I-L-E.\n",
      "Spelling mean and std: 0.143 +/- 0.279\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-R-I-M-U-P.\n",
      "Spelling mean and std: 0.212 +/- 0.251\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: radius -> R-A-S-I-N-T.\n",
      "Spelling mean and std: 0.049 +/- 0.282\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0246, 'grad_norm': 0.4066716432571411, 'learning_rate': 4.6168104980707107e-05, 'num_tokens': 17103.0, 'completions/mean_length': 11.55, 'completions/min_length': 9.4, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.55, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.15384893119335175, 'rewards/reward_spelling/std': 0.30556190609931944, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.153848934173584, 'reward_std': 0.2731006383895874, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.82}\n",
      "=====\n",
      "Completion example first line: eclipse -> E-C-E-L-P-O-R.\n",
      "Spelling mean and std: 0.096 +/- 0.148\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: gaze -> G-A-Z-E.\n",
      "Spelling mean and std: 0.460 +/- 0.340\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: echo -> E-C-H-R-O.\n",
      "Spelling mean and std: 0.162 +/- 0.132\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> Z-E-A-L-OUS.\n",
      "Spelling mean and std: 0.019 +/- 0.532\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: brawn -> B-R-A-N-E.\n",
      "Spelling mean and std: 0.211 +/- 0.155\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0044, 'grad_norm': 0.4645518362522125, 'learning_rate': 4.538902172398151e-05, 'num_tokens': 18808.0, 'completions/mean_length': 11.74285717010498, 'completions/min_length': 9.8, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.74285717010498, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.189699187874794, 'rewards/reward_spelling/std': 0.27952952682971954, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.1896992206573487, 'reward_std': 0.11631308645009994, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.04}\n",
      "=====\n",
      "Completion example first line: gaze -> G-A-Z-E.\n",
      "Spelling mean and std: 0.390 +/- 0.480\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fusion -> F-U-S-A-L.\n",
      "Spelling mean and std: 0.235 +/- 0.168\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sapphire -> S-AP-P-A-C-I-R.\n",
      "Spelling mean and std: 0.217 +/- 0.531\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: lantern -> L-A-N-P-R-T.\n",
      "Spelling mean and std: 0.135 +/- 0.213\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: wisp -> W-A-S-P.\n",
      "Spelling mean and std: 0.092 +/- 0.220\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0342, 'grad_norm': 0.4030078947544098, 'learning_rate': 4.454578706170075e-05, 'num_tokens': 20532.0, 'completions/mean_length': 12.0, 'completions/min_length': 9.4, 'completions/max_length': 15.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.0, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 15.4, 'rewards/reward_spelling/mean': 0.21365468353033065, 'rewards/reward_spelling/std': 0.3445455700159073, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2136547327041627, 'reward_std': 0.24532953053712844, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.21}\n",
      "=====\n",
      "Completion example first line: mirth -> M-I-R-N.\n",
      "Spelling mean and std: 0.508 +/- 0.180\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: knit -> N-I-K-T.\n",
      "Spelling mean and std: 0.101 +/- 0.297\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: plow -> P-L-O-W.\n",
      "Spelling mean and std: 0.518 +/- 0.354\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: gossipy -> G-S-O-U-P-I-Y.\n",
      "Spelling mean and std: 0.249 +/- 0.168\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-T-L-E.\n",
      "Spelling mean and std: 0.206 +/- 0.093\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0082, 'grad_norm': 0.33131343126296997, 'learning_rate': 4.364105412207914e-05, 'num_tokens': 22220.0, 'completions/mean_length': 11.2, 'completions/min_length': 9.4, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.2, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.31620047688484193, 'rewards/reward_spelling/std': 0.23358306288719177, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3162005186080932, 'reward_std': 0.19493823647499084, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.39}\n",
      "=====\n",
      "Completion example first line: mosaic -> M-A-S-I-T-I-A.\n",
      "Spelling mean and std: 0.175 +/- 0.143\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: resolve -> R-E-S-I-Z.\n",
      "Spelling mean and std: 0.239 +/- 0.315\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-I-R-U-M-P-H.\n",
      "Spelling mean and std: 0.375 +/- 0.364\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: relish -> R-E-L-Sh-E-R.\n",
      "Spelling mean and std: 0.599 +/- 0.365\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-A-N-N-O-R.\n",
      "Spelling mean and std: 0.502 +/- 0.298\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0086, 'grad_norm': 0.4997114837169647, 'learning_rate': 4.267766952966369e-05, 'num_tokens': 23950.0, 'completions/mean_length': 12.35, 'completions/min_length': 9.8, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.35, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.3779220819473267, 'rewards/reward_spelling/std': 0.31772297620773315, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3779220819473266, 'reward_std': 0.2393638461828232, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.57}\n",
      "=====\n",
      "Completion example first line: ember -> E-M-B-U-R.\n",
      "Spelling mean and std: 0.175 +/- 0.378\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: radius -> R-I-Z-O-R-A-S.\n",
      "Spelling mean and std: 0.250 +/- 0.235\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: prelude -> P-E-R-L-E-U-N.\n",
      "Spelling mean and std: 0.383 +/- 0.215\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> Z-E-A-L-U-S.\n",
      "Spelling mean and std: 0.343 +/- 0.414\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: oath -> O-H-A-L-T.\n",
      "Spelling mean and std: 0.274 +/- 0.334\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0131, 'grad_norm': 0.43059930205345154, 'learning_rate': 4.16586644488001e-05, 'num_tokens': 25655.0, 'completions/mean_length': 11.825, 'completions/min_length': 9.2, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.825, 'completions/min_terminated_length': 9.2, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.28493729829788206, 'rewards/reward_spelling/std': 0.3370325952768326, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2849372625350952, 'reward_std': 0.2643302589654922, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.75}\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-C-E-H-R.\n",
      "Spelling mean and std: 0.115 +/- 0.237\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-M-E.\n",
      "Spelling mean and std: 0.498 +/- 0.400\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-I-T-O.\n",
      "Spelling mean and std: -0.068 +/- 0.326\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.458 +/- 0.379\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mirage -> M-I-A-R-G-E.\n",
      "Spelling mean and std: 0.449 +/- 0.244\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0225, 'grad_norm': 0.4717034697532654, 'learning_rate': 4.058724504646834e-05, 'num_tokens': 27375.0, 'completions/mean_length': 12.2, 'completions/min_length': 9.4, 'completions/max_length': 15.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.2, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 15.4, 'rewards/reward_spelling/mean': 0.29067433178424834, 'rewards/reward_spelling/std': 0.33909712433815004, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2906743049621583, 'reward_std': 0.2998470664024353, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.93}\n",
      "=====\n",
      "Completion example first line: fathom -> F-I-H-A-M-E.\n",
      "Spelling mean and std: 0.080 +/- 0.145\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: veto -> V-E-T-O.\n",
      "Spelling mean and std: 0.383 +/- 0.319\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mosaic -> M-A-S-I-R-T.\n",
      "Spelling mean and std: 0.354 +/- 0.302\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: velvet -> V-A-L-E-T.\n",
      "Spelling mean and std: 0.438 +/- 0.360\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: glow -> G-L-O-V-R-I-N.\n",
      "Spelling mean and std: 0.208 +/- 0.197\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0265, 'grad_norm': 0.5054084062576294, 'learning_rate': 3.946678240449515e-05, 'num_tokens': 29111.0, 'completions/mean_length': 12.271428489685059, 'completions/min_length': 9.8, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.271428489685059, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.29263237714767454, 'rewards/reward_spelling/std': 0.28298177719116213, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2926323652267455, 'reward_std': 0.2601940155029297, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.14}\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-U-C-E.\n",
      "Spelling mean and std: 0.192 +/- 0.228\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-H-R-D.\n",
      "Spelling mean and std: 0.205 +/- 0.270\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aisle -> A-I-S-E-L.\n",
      "Spelling mean and std: 0.405 +/- 0.257\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> E-Z-A-L-O-S-I-A.\n",
      "Spelling mean and std: 0.092 +/- 0.359\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-T-O-S.\n",
      "Spelling mean and std: 0.036 +/- 0.488\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0311, 'grad_norm': 0.6598681807518005, 'learning_rate': 3.830080191288342e-05, 'num_tokens': 30841.0, 'completions/mean_length': 12.25, 'completions/min_length': 10.2, 'completions/max_length': 16.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.25, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 16.2, 'rewards/reward_spelling/mean': 0.18590299189090728, 'rewards/reward_spelling/std': 0.34254151582717896, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.185903000831604, 'reward_std': 0.2720237135887146, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.32}\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.572 +/- 0.307\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fusion -> F-V-I-A.\n",
      "Spelling mean and std: 0.136 +/- 0.218\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: lunar -> L-U-R-A-N.\n",
      "Spelling mean and std: 0.264 +/- 0.294\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: radius -> R-A-S-H-I-N.\n",
      "Spelling mean and std: 0.206 +/- 0.290\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: eclipse -> E-C-L-S-E-R-O.\n",
      "Spelling mean and std: 0.164 +/- 0.165\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0354, 'grad_norm': 0.33898845314979553, 'learning_rate': 3.7092972177631e-05, 'num_tokens': 32594.0, 'completions/mean_length': 12.925, 'completions/min_length': 10.6, 'completions/max_length': 18.4, 'completions/clipped_ratio': 0.025, 'completions/mean_terminated_length': 12.54285717010498, 'completions/min_terminated_length': 10.6, 'completions/max_terminated_length': 15.8, 'rewards/reward_spelling/mean': 0.26842657327651975, 'rewards/reward_spelling/std': 0.272355392575264, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2684265851974488, 'reward_std': 0.2546779215335846, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.5}\n",
      "=====\n",
      "Completion example first line: fathom -> F-O-R-H-M.\n",
      "Spelling mean and std: -0.008 +/- 0.245\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: grim -> G-R-M.\n",
      "Spelling mean and std: 0.286 +/- 0.398\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: tavern -> T-A-A-A-N.\n",
      "Spelling mean and std: 0.182 +/- 0.176\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: wisp -> W-P-I-S.\n",
      "Spelling mean and std: 0.359 +/- 0.267\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-M-E.\n",
      "Spelling mean and std: 0.482 +/- 0.384\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0216, 'grad_norm': 0.12748870253562927, 'learning_rate': 3.5847093477938956e-05, 'num_tokens': 34228.0, 'completions/mean_length': 10.25, 'completions/min_length': 8.2, 'completions/max_length': 13.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 10.25, 'completions/min_terminated_length': 8.2, 'completions/max_terminated_length': 13.0, 'rewards/reward_spelling/mean': 0.26018704026937484, 'rewards/reward_spelling/std': 0.3141813099384308, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2601870775222779, 'reward_std': 0.23912283033132553, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.68}\n",
      "=====\n",
      "Completion example first line: gaze -> G-A-Z-E.\n",
      "Spelling mean and std: 0.378 +/- 0.316\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: prelude -> P-R-I-L-E-U-N.\n",
      "Spelling mean and std: 0.270 +/- 0.223\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: resolve -> R-I-S-E.\n",
      "Spelling mean and std: 0.275 +/- 0.308\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: knit -> I-N-T-K.\n",
      "Spelling mean and std: 0.187 +/- 0.338\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: echo -> E-S-O-R-I-C.\n",
      "Spelling mean and std: 0.260 +/- 0.409\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0025, 'grad_norm': 0.5855076909065247, 'learning_rate': 3.456708580912725e-05, 'num_tokens': 35912.0, 'completions/mean_length': 11.4, 'completions/min_length': 9.0, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.4, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.27377345263957975, 'rewards/reward_spelling/std': 0.34103074967861174, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.273773455619812, 'reward_std': 0.2728495866060257, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.86}\n",
      "=====\n",
      "Completion example first line: summit -> S-U-M-T-I-A-R-E.\n",
      "Spelling mean and std: 0.199 +/- 0.227\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: frescos -> F. S. R. O. I. C.S.\n",
      "Spelling mean and std: 0.019 +/- 0.511\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-E-R-T-R-O-U-S.\n",
      "Spelling mean and std: 0.239 +/- 0.231\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: gossipy -> G-S-O-P-I-Y.\n",
      "Spelling mean and std: 0.256 +/- 0.145\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> Z-E-A-L-O-U-S.\n",
      "Spelling mean and std: 0.306 +/- 0.523\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.019, 'grad_norm': 0.6375958919525146, 'learning_rate': 3.3256976548879184e-05, 'num_tokens': 37728.0, 'completions/mean_length': 13.96428565979004, 'completions/min_length': 11.4, 'completions/max_length': 18.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 13.96428565979004, 'completions/min_terminated_length': 11.4, 'completions/max_terminated_length': 18.6, 'rewards/reward_spelling/mean': 0.20396270751953124, 'rewards/reward_spelling/std': 0.3499397933483124, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.1789627075195312, 'reward_std': 0.325581768155098, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.07}\n",
      "=====\n",
      "Completion example first line: idea -> I-D-E-A-T.\n",
      "Spelling mean and std: 0.357 +/- 0.371\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: relish -> R-E-L-S.\n",
      "Spelling mean and std: 0.466 +/- 0.300\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-M-E.\n",
      "Spelling mean and std: 0.527 +/- 0.287\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: frescos -> F-S-R-E-C-O-S.\n",
      "Spelling mean and std: 0.439 +/- 0.374\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fusion -> F-U-S-O-R-C.\n",
      "Spelling mean and std: 0.365 +/- 0.378\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "{'loss': -0.0115, 'grad_norm': 0.40037819743156433, 'learning_rate': 3.1920887785621235e-05, 'num_tokens': 39421.0, 'completions/mean_length': 11.425, 'completions/min_length': 9.2, 'completions/max_length': 13.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.425, 'completions/min_terminated_length': 9.2, 'completions/max_terminated_length': 13.4, 'rewards/reward_spelling/mean': 0.43090521097183226, 'rewards/reward_spelling/std': 0.3655384361743927, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.4059051990509033, 'reward_std': 0.34511707425117494, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.25}\n",
      "=====\n",
      "Completion example first line: velvet -> V-E-L-V-E.\n",
      "Spelling mean and std: 0.460 +/- 0.265\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: glow -> G-O-L-V.\n",
      "Spelling mean and std: 0.429 +/- 0.319\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: whistle -> W-H-I-C-S-H.\n",
      "Spelling mean and std: -0.181 +/- 0.405\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: mirth -> M-I-R-E.\n",
      "Spelling mean and std: 0.542 +/- 0.225\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fathom -> F-A-M-H-T.\n",
      "Spelling mean and std: 0.234 +/- 0.388\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0002, 'grad_norm': 0.48203814029693604, 'learning_rate': 3.056302334890786e-05, 'num_tokens': 41081.0, 'completions/mean_length': 10.7, 'completions/min_length': 9.0, 'completions/max_length': 13.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 10.7, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 13.0, 'rewards/reward_spelling/mean': 0.29642024338245393, 'rewards/reward_spelling/std': 0.34251275658607483, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.2714202404022217, 'reward_std': 0.3313847124576569, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.43}\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-R-E-V-E.\n",
      "Spelling mean and std: 0.067 +/- 0.151\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-N-A-R-N-E.\n",
      "Spelling mean and std: 0.195 +/- 0.401\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-I-R-U-V-I-M.\n",
      "Spelling mean and std: 0.542 +/- 0.163\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: scarab -> S-A-R-C-A-R.\n",
      "Spelling mean and std: 0.446 +/- 0.271\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-S-M-D.\n",
      "Spelling mean and std: 0.087 +/- 0.174\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0338, 'grad_norm': 0.6131789684295654, 'learning_rate': 2.918765558261841e-05, 'num_tokens': 42791.0, 'completions/mean_length': 11.95, 'completions/min_length': 9.8, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.95, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.26756023466587064, 'rewards/reward_spelling/std': 0.2482452392578125, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2675601959228515, 'reward_std': 0.22319462299346923, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.61}\n",
      "=====\n",
      "Completion example first line: tavern -> T-A-A-N-B.\n",
      "Spelling mean and std: 0.484 +/- 0.321\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: oath -> O-A-H-T.\n",
      "Spelling mean and std: 0.299 +/- 0.244\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sphinx -> S-P-H-Q-N-I.\n",
      "Spelling mean and std: 0.299 +/- 0.268\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-T-U-R-D.\n",
      "Spelling mean and std: 0.062 +/- 0.204\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-R-A-T-E-R.\n",
      "Spelling mean and std: 0.520 +/- 0.135\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0036, 'grad_norm': 0.33473214507102966, 'learning_rate': 2.7799111902582696e-05, 'num_tokens': 44493.0, 'completions/mean_length': 11.45, 'completions/min_length': 8.6, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.45, 'completions/min_terminated_length': 8.6, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.33268566355109214, 'rewards/reward_spelling/std': 0.250428295135498, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.332685685157776, 'reward_std': 0.16854295134544373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.79}\n",
      "=====\n",
      "Completion example first line: brawn -> B-R-A-N.\n",
      "Spelling mean and std: 0.314 +/- 0.253\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: elude -> E-L-E-U-D.\n",
      "Spelling mean and std: 0.500 +/- 0.309\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-C-A-D.\n",
      "Spelling mean and std: 0.191 +/- 0.193\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: enchant -> E-N-C-A-P-T.\n",
      "Spelling mean and std: 0.096 +/- 0.210\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: radius -> R-S-A-M-R.\n",
      "Spelling mean and std: -0.021 +/- 0.191\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0128, 'grad_norm': 0.4962092339992523, 'learning_rate': 2.6401761180929797e-05, 'num_tokens': 46207.0, 'completions/mean_length': 12.10714282989502, 'completions/min_length': 10.6, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.10714282989502, 'completions/min_terminated_length': 10.6, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.2160256437957287, 'rewards/reward_spelling/std': 0.2472094178199768, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2160256385803223, 'reward_std': 0.23619371950626372, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.96}\n",
      "=====\n",
      "Completion example first line: grim -> G-R-M.\n",
      "Spelling mean and std: 0.370 +/- 0.163\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: summit -> S-U-M-T-I-N.\n",
      "Spelling mean and std: 0.330 +/- 0.257\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: tavern -> T-A-A-N-A.\n",
      "Spelling mean and std: 0.301 +/- 0.321\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-I-E-R-U.\n",
      "Spelling mean and std: 0.282 +/- 0.227\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.659 +/- 0.251\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0001, 'grad_norm': 0.3330608606338501, 'learning_rate': 2.5e-05, 'num_tokens': 47896.0, 'completions/mean_length': 11.525, 'completions/min_length': 9.2, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.525, 'completions/min_terminated_length': 9.2, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.38810078501701356, 'rewards/reward_spelling/std': 0.26076086461544035, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.363100814819336, 'reward_std': 0.20333715826272963, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.18}\n",
      "=====\n",
      "Completion example first line: mirth -> M-I-R-T.\n",
      "Spelling mean and std: 0.471 +/- 0.172\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: knit -> N-I-T.\n",
      "Spelling mean and std: 0.067 +/- 0.369\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-R-P-E-R-T-U-R-E.\n",
      "Spelling mean and std: 0.226 +/- 0.268\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: velvet -> V-L-E-V-T.\n",
      "Spelling mean and std: 0.341 +/- 0.345\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-M-E.\n",
      "Spelling mean and std: 0.448 +/- 0.440\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0144, 'grad_norm': 0.30992183089256287, 'learning_rate': 2.3598238819070202e-05, 'num_tokens': 49634.0, 'completions/mean_length': 12.25, 'completions/min_length': 9.4, 'completions/max_length': 15.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.25, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 15.4, 'rewards/reward_spelling/mean': 0.31058607399463656, 'rewards/reward_spelling/std': 0.3409964472055435, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3105860948562622, 'reward_std': 0.22303422689437866, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.36}\n",
      "=====\n",
      "Completion example first line: elude -> E-L-E-U-D.\n",
      "Spelling mean and std: 0.283 +/- 0.132\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ember -> E-M-B-U-E.\n",
      "Spelling mean and std: 0.456 +/- 0.207\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: crisp -> C-R-I-S-P.\n",
      "Spelling mean and std: 0.514 +/- 0.358\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: prelude -> P-A-R-I-L-O-U-N.\n",
      "Spelling mean and std: 0.478 +/- 0.323\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: torrent -> T-O-R-A-N.\n",
      "Spelling mean and std: 0.260 +/- 0.210\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0231, 'grad_norm': 0.4550982713699341, 'learning_rate': 2.2200888097417307e-05, 'num_tokens': 51366.0, 'completions/mean_length': 12.2, 'completions/min_length': 10.2, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.2, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.39803253412246703, 'rewards/reward_spelling/std': 0.2630049139261246, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3980325222015382, 'reward_std': 0.22744749039411544, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.54}\n",
      "=====\n",
      "Completion example first line: relish -> R-E-S-L-I-R.\n",
      "Spelling mean and std: 0.419 +/- 0.274\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-A-N-N-O-R.\n",
      "Spelling mean and std: 0.455 +/- 0.291\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: scarab -> S-A-R-K-A-B.\n",
      "Spelling mean and std: 0.432 +/- 0.213\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-N-S-I-D.\n",
      "Spelling mean and std: 0.453 +/- 0.109\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: oath -> O-A-H-T.\n",
      "Spelling mean and std: 0.430 +/- 0.268\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0111, 'grad_norm': 0.47968295216560364, 'learning_rate': 2.0812344417381595e-05, 'num_tokens': 53096.0, 'completions/mean_length': 12.15, 'completions/min_length': 10.2, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.15, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.4377777874469757, 'rewards/reward_spelling/std': 0.24702873080968857, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.412777805328369, 'reward_std': 0.2480123072862625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.71}\n",
      "=====\n",
      "Completion example first line: resolve -> R-E-S-I-V-E.\n",
      "Spelling mean and std: 0.141 +/- 0.146\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: whistle -> W-H-I-C-L.\n",
      "Spelling mean and std: 0.004 +/- 0.166\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: capture -> C-A-P-U-R-E.\n",
      "Spelling mean and std: 0.176 +/- 0.148\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-A-C-H-R.\n",
      "Spelling mean and std: 0.000 +/- 0.115\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aisle -> A-I-S-L-E.\n",
      "Spelling mean and std: 0.448 +/- 0.381\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0023, 'grad_norm': 0.38343796133995056, 'learning_rate': 1.9436976651092144e-05, 'num_tokens': 54786.0, 'completions/mean_length': 11.75, 'completions/min_length': 9.0, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.75, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.15394327696412802, 'rewards/reward_spelling/std': 0.20444554537534715, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.1539433002471924, 'reward_std': 0.18264871090650558, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.89}\n",
      "=====\n",
      "Completion example first line: verge -> V-E-R-G.\n",
      "Spelling mean and std: 0.567 +/- 0.354\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: gaze -> G-A-Z-E-E.\n",
      "Spelling mean and std: 0.383 +/- 0.318\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: gossipy -> G-S-O-O-P-I-Y.\n",
      "Spelling mean and std: 0.514 +/- 0.226\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: velvet -> V-E-L-O-V-T.\n",
      "Spelling mean and std: 0.409 +/- 0.337\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: grim -> G-R-H-I-M.\n",
      "Spelling mean and std: 0.164 +/- 0.123\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0014, 'grad_norm': 0.5587992668151855, 'learning_rate': 1.8079112214378768e-05, 'num_tokens': 56449.0, 'completions/mean_length': 10.68928565979004, 'completions/min_length': 9.0, 'completions/max_length': 12.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 10.68928565979004, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 12.2, 'rewards/reward_spelling/mean': 0.40743701457977294, 'rewards/reward_spelling/std': 0.2903218775987625, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.407436990737915, 'reward_std': 0.2021330863237381, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.11}\n",
      "=====\n",
      "Completion example first line: capture -> C-A-U-P-H-R-E.\n",
      "Spelling mean and std: 0.135 +/- 0.171\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-T-O-S.\n",
      "Spelling mean and std: 0.161 +/- 0.315\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-N-A-B-N-I-R.\n",
      "Spelling mean and std: 0.419 +/- 0.391\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: elude -> E-L-U-E.\n",
      "Spelling mean and std: 0.314 +/- 0.278\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: torrent -> T-O-R-A-N.\n",
      "Spelling mean and std: 0.438 +/- 0.354\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0276, 'grad_norm': 0.484790563583374, 'learning_rate': 1.6743023451120832e-05, 'num_tokens': 58163.0, 'completions/mean_length': 11.85, 'completions/min_length': 9.4, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.85, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.2932595252990723, 'rewards/reward_spelling/std': 0.32266081869602203, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.293259572982788, 'reward_std': 0.28416432440280914, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.29}\n",
      "=====\n",
      "Completion example first line: mosaic -> M-A-S-I-T-R.\n",
      "Spelling mean and std: 0.318 +/- 0.210\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-R-I-M-P-H.\n",
      "Spelling mean and std: 0.304 +/- 0.323\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mirth -> M-I-R-T.\n",
      "Spelling mean and std: 0.302 +/- 0.152\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: expose -> E-X-P-S-H-E-R.\n",
      "Spelling mean and std: 0.156 +/- 0.184\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-R-P-E-R-T-E.\n",
      "Spelling mean and std: 0.222 +/- 0.153\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0335, 'grad_norm': 0.5450782179832458, 'learning_rate': 1.5432914190872757e-05, 'num_tokens': 59910.0, 'completions/mean_length': 12.575, 'completions/min_length': 10.0, 'completions/max_length': 15.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.575, 'completions/min_terminated_length': 10.0, 'completions/max_terminated_length': 15.4, 'rewards/reward_spelling/mean': 0.2603058129549026, 'rewards/reward_spelling/std': 0.2186694860458374, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2603058338165283, 'reward_std': 0.18131131082773208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.46}\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-I-C-E-U-R.\n",
      "Spelling mean and std: 0.095 +/- 0.142\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-C-H-E-D.\n",
      "Spelling mean and std: 0.410 +/- 0.315\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-T-P-R-E-L.\n",
      "Spelling mean and std: 0.352 +/- 0.251\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: relish -> R-E-L-L-I-S.\n",
      "Spelling mean and std: 0.395 +/- 0.127\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: scarab -> S-C-A-R-A-B.\n",
      "Spelling mean and std: 0.143 +/- 0.352\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0019, 'grad_norm': 0.3982425034046173, 'learning_rate': 1.4152906522061048e-05, 'num_tokens': 61644.0, 'completions/mean_length': 12.25, 'completions/min_length': 10.2, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.25, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.27915418446063994, 'rewards/reward_spelling/std': 0.2539604663848877, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2791541814804077, 'reward_std': 0.20450593084096907, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.64}\n",
      "=====\n",
      "Completion example first line: resolve -> R-E-S-I-S-E.\n",
      "Spelling mean and std: 0.114 +/- 0.160\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: brawn -> B-A-R-N-E.\n",
      "Spelling mean and std: 0.583 +/- 0.332\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ember -> E-M-B-I-U-R.\n",
      "Spelling mean and std: 0.330 +/- 0.235\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-N-S-T.\n",
      "Spelling mean and std: 0.425 +/- 0.236\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: idea -> I-D-A-I-T.\n",
      "Spelling mean and std: 0.571 +/- 0.350\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0251, 'grad_norm': 0.4891226887702942, 'learning_rate': 1.2907027822369005e-05, 'num_tokens': 63288.0, 'completions/mean_length': 10.7, 'completions/min_length': 9.4, 'completions/max_length': 13.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 10.7, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 13.0, 'rewards/reward_spelling/mean': 0.40458431243896487, 'rewards/reward_spelling/std': 0.28073286414146426, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.4045843362808228, 'reward_std': 0.1869152382016182, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.82}\n",
      "=====\n",
      "Completion example first line: knit -> N-I-K-T.\n",
      "Spelling mean and std: -0.021 +/- 0.227\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: maze -> M-A-Z-E.\n",
      "Spelling mean and std: 0.471 +/- 0.386\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: verge -> V-E-R-G-E.\n",
      "Spelling mean and std: 0.588 +/- 0.220\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sphinx -> S-P-H-I-N-I.\n",
      "Spelling mean and std: 0.633 +/- 0.233\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-U-T.\n",
      "Spelling mean and std: 0.158 +/- 0.258\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0032, 'grad_norm': 0.6179556846618652, 'learning_rate': 1.1699198087116589e-05, 'num_tokens': 65005.0, 'completions/mean_length': 11.73214282989502, 'completions/min_length': 9.4, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.73214282989502, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.3657870016992092, 'rewards/reward_spelling/std': 0.28288498520851135, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3657869815826416, 'reward_std': 0.23689835369586945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.04}\n",
      "=====\n",
      "Completion example first line: torrent -> T-O-R-U-R-A.\n",
      "Spelling mean and std: 0.378 +/- 0.307\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ember -> E-M-R-I-U.\n",
      "Spelling mean and std: 0.173 +/- 0.345\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fathom -> F-A-M-T-I-N.\n",
      "Spelling mean and std: 0.084 +/- 0.139\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: cipher -> C-A-P-I-Z-O.\n",
      "Spelling mean and std: 0.330 +/- 0.328\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: verge -> V-E-R-G-U-E.\n",
      "Spelling mean and std: 0.247 +/- 0.377\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "{'loss': -0.0248, 'grad_norm': 0.47740501165390015, 'learning_rate': 1.0533217595504858e-05, 'num_tokens': 66702.0, 'completions/mean_length': 11.625, 'completions/min_length': 8.8, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.625, 'completions/min_terminated_length': 8.8, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.24238817095756532, 'rewards/reward_spelling/std': 0.3198390692472458, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.2173882246017456, 'reward_std': 0.3192929044365883, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.21}\n",
      "=====\n",
      "Completion example first line: brawn -> B-R-A-N-E.\n",
      "Spelling mean and std: 0.315 +/- 0.262\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.736 +/- 0.200\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: grim -> G-R-M-E.\n",
      "Spelling mean and std: 0.443 +/- 0.268\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-M-E.\n",
      "Spelling mean and std: 0.414 +/- 0.501\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: lantern -> L-A-N-P-I-N.\n",
      "Spelling mean and std: 0.326 +/- 0.248\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.003, 'grad_norm': 0.3084251582622528, 'learning_rate': 9.412754953531663e-06, 'num_tokens': 68408.0, 'completions/mean_length': 11.85, 'completions/min_length': 9.0, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.85, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.4468947768211365, 'rewards/reward_spelling/std': 0.31605827808380127, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.4218947887420654, 'reward_std': 0.31307687014341357, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.39}\n",
      "=====\n",
      "Completion example first line: lunar -> L-U-R-N-A.\n",
      "Spelling mean and std: 0.253 +/- 0.133\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-R-E-U.\n",
      "Spelling mean and std: 0.291 +/- 0.251\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-N-S-H-L-E.\n",
      "Spelling mean and std: 0.333 +/- 0.364\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: scarab -> S-A-C-R-A-B.\n",
      "Spelling mean and std: 0.136 +/- 0.249\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-P-T-L-E.\n",
      "Spelling mean and std: 0.464 +/- 0.257\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0035, 'grad_norm': 0.33936500549316406, 'learning_rate': 8.341335551199902e-06, 'num_tokens': 70108.0, 'completions/mean_length': 11.7, 'completions/min_length': 9.0, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.7, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.2955433577299118, 'rewards/reward_spelling/std': 0.2680258572101593, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.2705433368682861, 'reward_std': 0.2820591628551483, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.57}\n",
      "=====\n",
      "Completion example first line: oath -> O-A-H-R-I.\n",
      "Spelling mean and std: 0.357 +/- 0.181\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> Z-E-A-L-O-U-S.\n",
      "Spelling mean and std: 0.790 +/- 0.191\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: maze -> M-A-Z-E.\n",
      "Spelling mean and std: 0.464 +/- 0.450\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-R-I-M-P-H.\n",
      "Spelling mean and std: 0.504 +/- 0.253\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: relish -> R-E-S-L-I-R-E.\n",
      "Spelling mean and std: 0.136 +/- 0.079\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0272, 'grad_norm': 0.32475921511650085, 'learning_rate': 7.3223304703363135e-06, 'num_tokens': 71808.0, 'completions/mean_length': 11.4, 'completions/min_length': 9.8, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.4, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.4504245787858963, 'rewards/reward_spelling/std': 0.2466804027557373, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.450424575805664, 'reward_std': 0.22199859470129013, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.75}\n",
      "=====\n",
      "Completion example first line: frescos -> F-R-S-O-C-S.\n",
      "Spelling mean and std: 0.250 +/- 0.223\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: capture -> C-U-R-P.\n",
      "Spelling mean and std: 0.012 +/- 0.259\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: plow -> P-L-O-W.\n",
      "Spelling mean and std: 0.531 +/- 0.349\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: wisp -> W-E-P-I-S.\n",
      "Spelling mean and std: 0.429 +/- 0.404\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-R-E-T-U-R-E.\n",
      "Spelling mean and std: 0.189 +/- 0.255\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0041, 'grad_norm': 0.35760173201560974, 'learning_rate': 6.358945877920861e-06, 'num_tokens': 73514.0, 'completions/mean_length': 11.65, 'completions/min_length': 9.8, 'completions/max_length': 15.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.65, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 15.4, 'rewards/reward_spelling/mean': 0.28223443292081357, 'rewards/reward_spelling/std': 0.3185992270708084, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2822344779968262, 'reward_std': 0.20204001069068908, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.93}\n",
      "=====\n",
      "Completion example first line: whistle -> W-H-I-C-E.\n",
      "Spelling mean and std: 0.269 +/- 0.149\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sapphire -> S-AP-P-I-R-H.\n",
      "Spelling mean and std: 0.393 +/- 0.476\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: void -> V-T-I-O.\n",
      "Spelling mean and std: 0.212 +/- 0.261\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: triumph -> T-I-R-U-M-P-H.\n",
      "Spelling mean and std: 0.452 +/- 0.156\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: summit -> S-M-U-T.\n",
      "Spelling mean and std: 0.318 +/- 0.426\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0149, 'grad_norm': 0.5827116966247559, 'learning_rate': 5.454212938299258e-06, 'num_tokens': 75244.0, 'completions/mean_length': 12.128571510314941, 'completions/min_length': 9.8, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.128571510314941, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.3288988769054413, 'rewards/reward_spelling/std': 0.3139923125505447, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3288988590240478, 'reward_std': 0.2581118017435074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.14}\n",
      "=====\n",
      "Completion example first line: eclipse -> E-C-L-O-P-I-N.\n",
      "Spelling mean and std: 0.408 +/- 0.379\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: veto -> V-E-O-T-O.\n",
      "Spelling mean and std: 0.424 +/- 0.361\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: enchant -> E-N-C-A-N-T.\n",
      "Spelling mean and std: 0.291 +/- 0.371\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: scarab -> S-A-R-C-A-B.\n",
      "Spelling mean and std: 0.516 +/- 0.281\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mirage -> M-I-R-A-G.\n",
      "Spelling mean and std: 0.531 +/- 0.136\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0166, 'grad_norm': 0.34688714146614075, 'learning_rate': 4.610978276018496e-06, 'num_tokens': 76938.0, 'completions/mean_length': 11.45, 'completions/min_length': 9.4, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.45, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.43394105434417723, 'rewards/reward_spelling/std': 0.3267134755849838, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.4339410543441773, 'reward_std': 0.2791299521923065, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.32}\n",
      "=====\n",
      "Completion example first line: gossipy -> G-O-S-H-O-P.\n",
      "Spelling mean and std: 0.609 +/- 0.238\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-N-D-S.\n",
      "Spelling mean and std: 0.190 +/- 0.113\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-R-E-T-O-R-U-T.\n",
      "Spelling mean and std: 0.568 +/- 0.288\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: maze -> M-A-Z-I-A.\n",
      "Spelling mean and std: 0.317 +/- 0.332\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: resolve -> E-S-R-O-V-S.\n",
      "Spelling mean and std: 0.191 +/- 0.171\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0107, 'grad_norm': 0.46759119629859924, 'learning_rate': 3.831895019292897e-06, 'num_tokens': 78638.0, 'completions/mean_length': 11.7, 'completions/min_length': 9.4, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.7, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.3751709580421448, 'rewards/reward_spelling/std': 0.2442186191678047, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3751709699630736, 'reward_std': 0.19476162046194076, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.5}\n",
      "=====\n",
      "Completion example first line: ember -> E-B-U-M.\n",
      "Spelling mean and std: 0.216 +/- 0.211\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: banner -> B-N-A-B-N-R.\n",
      "Spelling mean and std: 0.375 +/- 0.293\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: knit -> L-I-T-H-E.\n",
      "Spelling mean and std: 0.304 +/- 0.497\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fathom -> F-H-O-R-T.\n",
      "Spelling mean and std: 0.217 +/- 0.289\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: whistle -> W-H-I-C-L.\n",
      "Spelling mean and std: 0.261 +/- 0.265\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0079, 'grad_norm': 0.5841069221496582, 'learning_rate': 3.119414452281158e-06, 'num_tokens': 80312.0, 'completions/mean_length': 11.15, 'completions/min_length': 9.4, 'completions/max_length': 12.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.15, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 12.6, 'rewards/reward_spelling/mean': 0.274467208981514, 'rewards/reward_spelling/std': 0.3323596715927124, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.2744672060012818, 'reward_std': 0.22517231106758118, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.68}\n",
      "=====\n",
      "Completion example first line: relish -> R-E-S-L-E.\n",
      "Spelling mean and std: 0.232 +/- 0.160\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: echo -> E-C-R-H-E.\n",
      "Spelling mean and std: 0.088 +/- 0.161\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: crisp -> C-R-I-S-P.\n",
      "Spelling mean and std: 0.391 +/- 0.390\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-C-H-E-D.\n",
      "Spelling mean and std: 0.549 +/- 0.261\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: brawn -> B-R-A-N-W.\n",
      "Spelling mean and std: 0.352 +/- 0.269\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0248, 'grad_norm': 0.47467973828315735, 'learning_rate': 2.475778302439524e-06, 'num_tokens': 82034.0, 'completions/mean_length': 11.95, 'completions/min_length': 10.2, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.95, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.3224608778953552, 'rewards/reward_spelling/std': 0.2653311163187027, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.322460913658142, 'reward_std': 0.1966535896062851, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.86}\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-P-T-L-E.\n",
      "Spelling mean and std: 0.591 +/- 0.221\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: rust -> R-U-T-S.\n",
      "Spelling mean and std: 0.287 +/- 0.322\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mosaic -> M-A-S-T-I-R.\n",
      "Spelling mean and std: 0.193 +/- 0.278\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: cipher -> C-A-F-I-P.\n",
      "Spelling mean and std: 0.268 +/- 0.295\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: capture -> C-U-P-H-E-R.\n",
      "Spelling mean and std: 0.288 +/- 0.195\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.012, 'grad_norm': 0.27071133255958557, 'learning_rate': 1.9030116872178316e-06, 'num_tokens': 83772.0, 'completions/mean_length': 12.43928565979004, 'completions/min_length': 10.6, 'completions/max_length': 15.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.43928565979004, 'completions/min_terminated_length': 10.6, 'completions/max_terminated_length': 15.0, 'rewards/reward_spelling/mean': 0.32546343803405764, 'rewards/reward_spelling/std': 0.2802561968564987, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.3254634380340575, 'reward_std': 0.22781273126602172, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.07}\n",
      "=====\n",
      "Completion example first line: lantern -> L-A-N-T-H-R.\n",
      "Spelling mean and std: 0.481 +/- 0.114\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: veto -> V-O-T-I.\n",
      "Spelling mean and std: 0.315 +/- 0.250\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: echo -> E-K-H-R-E.\n",
      "Spelling mean and std: 0.170 +/- 0.229\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: summit -> S-M-U-T-I-N.\n",
      "Spelling mean and std: 0.113 +/- 0.395\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: fathom -> F-A-M-T-H.\n",
      "Spelling mean and std: 0.013 +/- 0.150\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': 0.0028, 'grad_norm': 0.692669153213501, 'learning_rate': 1.4029167422908107e-06, 'num_tokens': 85466.0, 'completions/mean_length': 11.45, 'completions/min_length': 10.6, 'completions/max_length': 13.4, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.45, 'completions/min_terminated_length': 10.6, 'completions/max_terminated_length': 13.4, 'rewards/reward_spelling/mean': 0.21838162168860437, 'rewards/reward_spelling/std': 0.24326322823762894, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.1933816075325012, 'reward_std': 0.2611928373575211, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.25}\n",
      "=====\n",
      "Completion example first line: mantle -> M-A-T-L-E-N.\n",
      "Spelling mean and std: 0.352 +/- 0.259\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: zealous -> ZA-EL-O-R-U-S.\n",
      "Spelling mean and std: 0.437 +/- 0.351\n",
      "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
      "=====\n",
      "Completion example first line: elude -> E-L-U-D-E.\n",
      "Spelling mean and std: 0.464 +/- 0.343\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: aperture -> A-P-R-E-T-U-R.\n",
      "Spelling mean and std: -0.106 +/- 0.468\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: plow -> P-L-O-W.\n",
      "Spelling mean and std: 0.700 +/- 0.252\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0009, 'grad_norm': 0.5100094676017761, 'learning_rate': 9.770669513725128e-07, 'num_tokens': 87183.0, 'completions/mean_length': 12.025, 'completions/min_length': 9.4, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 12.025, 'completions/min_terminated_length': 9.4, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.36944944858551027, 'rewards/reward_spelling/std': 0.35753297805786133, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 0.975, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.07071067690849304, 'reward': 1.3444494485855103, 'reward_std': 0.33977551758289337, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.43}\n",
      "=====\n",
      "Completion example first line: rust -> R-T-O-R-D.\n",
      "Spelling mean and std: 0.084 +/- 0.183\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: torrent -> T-O-R-A-R-T.\n",
      "Spelling mean and std: 0.110 +/- 0.170\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: ivory -> I-V-O-R-Y.\n",
      "Spelling mean and std: 0.778 +/- 0.192\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sapphire -> S-A-P-I-R-H.\n",
      "Spelling mean and std: 0.146 +/- 0.203\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: orchard -> O-R-A-D-H.\n",
      "Spelling mean and std: 0.298 +/- 0.323\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0186, 'grad_norm': 0.6643492579460144, 'learning_rate': 6.268021954544096e-07, 'num_tokens': 88899.0, 'completions/mean_length': 11.8, 'completions/min_length': 9.8, 'completions/max_length': 14.6, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.8, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 14.6, 'rewards/reward_spelling/mean': 0.2833177983760834, 'rewards/reward_spelling/std': 0.22906242907047272, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.28331778049469, 'reward_std': 0.18906070590019225, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.61}\n",
      "=====\n",
      "Completion example first line: absolve -> A-B-E-U-R-S-E.\n",
      "Spelling mean and std: 0.291 +/- 0.279\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: mosaic -> M-A-S-I-T.\n",
      "Spelling mean and std: 0.323 +/- 0.145\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: onset -> O-N-S-H-T.\n",
      "Spelling mean and std: 0.319 +/- 0.259\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: fume -> F-U-E-M-E.\n",
      "Spelling mean and std: 0.571 +/- 0.350\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: resolve -> R-E-S-I-S-H.\n",
      "Spelling mean and std: 0.357 +/- 0.149\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0267, 'grad_norm': 0.27866634726524353, 'learning_rate': 3.5322453704410286e-07, 'num_tokens': 90589.0, 'completions/mean_length': 11.45, 'completions/min_length': 9.8, 'completions/max_length': 13.8, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.45, 'completions/min_terminated_length': 9.8, 'completions/max_terminated_length': 13.8, 'rewards/reward_spelling/mean': 0.3724692165851593, 'rewards/reward_spelling/std': 0.25258963108062743, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.372469186782837, 'reward_std': 0.2374282404780388, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.79}\n",
      "=====\n",
      "Completion example first line: mirth -> M-I-R-T.\n",
      "Spelling mean and std: 0.419 +/- 0.223\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: sphinx -> S-P-H-I-N-E.\n",
      "Spelling mean and std: 0.688 +/- 0.198\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: velvet -> V-O-L-V-E.\n",
      "Spelling mean and std: 0.390 +/- 0.294\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: maze -> M-A-S-E-Z.\n",
      "Spelling mean and std: 0.514 +/- 0.258\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "=====\n",
      "Completion example first line: void -> V-O-T.\n",
      "Spelling mean and std: 0.125 +/- 0.226\n",
      "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
      "{'loss': -0.0053, 'grad_norm': 0.55169677734375, 'learning_rate': 1.571947526689349e-07, 'num_tokens': 92289.0, 'completions/mean_length': 11.53571434020996, 'completions/min_length': 9.0, 'completions/max_length': 14.2, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 11.53571434020996, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 14.2, 'rewards/reward_spelling/mean': 0.4272144615650177, 'rewards/reward_spelling/std': 0.2563472092151642, 'rewards/reward_response_in_form_of_letter_dash_letter/mean': 1.0, 'rewards/reward_response_in_form_of_letter_dash_letter/std': 0.0, 'reward': 1.4272144556045532, 'reward_std': 0.22189232110977172, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 9.96}\n",
      "{'train_runtime': 183.29, 'train_samples_per_second': 3.001, 'train_steps_per_second': 1.528, 'train_loss': 0.0006719554836982516, 'epoch': 9.96}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=270, training_loss=0.0006719554836982516, metrics={'train_runtime': 183.29, 'train_samples_per_second': 3.001, 'train_steps_per_second': 1.528, 'total_flos': 0.0, 'train_loss': 0.0006719554836982516})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student task: Set the GRPOConfig and initialize the trainer\n",
    "# See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
    "# TODO: Complete the sections with **********\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"data/spelling-grpo\",\n",
    "    max_completion_length=30,\n",
    "    logging_steps=5,\n",
    "    # learning_rate=**********,\n",
    "    # num_train_epochs=**********,\n",
    "    # per_device_train_batch_size=**********,\n",
    "    # num_generations=**********,\n",
    "    # lr_scheduler_type=**********,\n",
    "    # beta=**********,\n",
    "    # <<< START SOLUTION SECTION\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,  # We'll train just for a few epochs\n",
    "    per_device_train_batch_size=8,  # The batch size for training\n",
    "    num_generations=4,  # Determines the number of completions to compute for each single prompt\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    beta=0.0,\n",
    "    # >>> END SOLUTION SECTION\n",
    ")\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    # Add the parameter for the reward functions\n",
    "    # **********\n",
    "    # <<< START SOLUTION SECTION\n",
    "    reward_funcs=[\n",
    "        reward_spelling,\n",
    "        reward_response_in_form_of_letter_dash_letter,\n",
    "    ],\n",
    "    # >>> END SOLUTION SECTION\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d14200",
   "metadata": {},
   "source": [
    "Now we define the `SFTTrainer` and run the fine-tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c443c",
   "metadata": {},
   "source": [
    "## Step 5. Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f806e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: T-R-I-U-M-P-H. | Actual: T-R-I-U-M-P-H. | Matches: ✅\n",
      "Proposed: S-A-P-I-C-R-H. | Actual: S-A-P-P-H-I-R-E. | Matches: ❌\n",
      "Proposed: E-X-P-S-E. | Actual: E-X-P-O-S-E. | Matches: ❌\n",
      "Proposed: F-R-S-E-C-O-S. | Actual: F-R-E-S-C-O-S. | Matches: ❌\n",
      "Proposed: W-I-P-S. | Actual: W-I-S-P. | Matches: ❌\n",
      "Proposed: M-I-R-A-G. | Actual: M-I-R-A-G-E. | Matches: ❌\n",
      "Proposed: I-V-O-R-Y. | Actual: I-V-O-R-Y. | Matches: ✅\n",
      "Proposed: O-N-S-H-D. | Actual: O-N-S-E-T. | Matches: ❌\n",
      "Proposed: E-L-U-D-E. | Actual: E-L-U-D-E. | Matches: ✅\n",
      "Proposed: S-P-H-I-N-X. | Actual: S-P-H-I-N-X. | Matches: ✅\n",
      "Proposed: B-R-A-N-Y. | Actual: B-R-A-W-N. | Matches: ❌\n",
      "Proposed: G-O-S-H-O-P-I. | Actual: G-O-S-S-I-P-Y. | Matches: ❌\n",
      "Proposed: E-N-C-H-A-N. | Actual: E-N-C-H-A-N-T. | Matches: ❌\n",
      "Proposed: T-A-A-N-R. | Actual: T-A-V-E-R-N. | Matches: ❌\n",
      "Proposed: W-H-I-C-E. | Actual: W-H-I-S-T-L-E. | Matches: ❌\n",
      "Proposed: C-U-P-H-E-R. | Actual: C-A-P-T-U-R-E. | Matches: ❌\n",
      "Proposed: E-C-H-R-E. | Actual: E-C-H-O. | Matches: ❌\n",
      "Proposed: M-I-R-T. | Actual: M-I-R-T-H. | Matches: ❌\n",
      "Proposed: C-R-I-S-P. | Actual: C-R-I-S-P. | Matches: ✅\n",
      "Proposed: Z-E-A-L-O-U-S. | Actual: Z-E-A-L-O-U-S. | Matches: ✅\n",
      "13.979761904761904/20.0 words correct\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model on the same training examples\n",
    "# No changes needed in this cell\n",
    "\n",
    "proportion_correct = 0.0\n",
    "\n",
    "for example in ds[\"train\"].select(range(20)):\n",
    "    prompt = example[\"prompt\"]\n",
    "    completion = example[\"completion\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=completion,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/20.0 words correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfe48f",
   "metadata": {},
   "source": [
    "The model now performs better on the training data it has seen. But has it generalized? Let's check its performance on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af0bab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed: W-R-Y-I-L-Y. | Actual: W-R-Y-L-Y. | Matches: ❌\n",
      "Proposed: G-L-I-N-E. | Actual: G-L-I-S-T-E-N. | Matches: ❌\n",
      "Proposed: C-A-S-E. | Actual: Q-U-E-S-T. | Matches: ❌\n",
      "Proposed: C-E-R-A-V. | Actual: C-R-A-V-E. | Matches: ❌\n",
      "Proposed: L-U-S-I-R-O. | Actual: L-U-S-H. | Matches: ❌\n",
      "Proposed: F-A-L-I-C-E. | Actual: F-A-B-L-E. | Matches: ❌\n",
      "Proposed: K-N-A-R-C-E. | Actual: K-N-A-C-K. | Matches: ❌\n",
      "2.6416666666666666/7.0 words correct\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model on the unseen test set\n",
    "# No changes needed in this cell\n",
    "\n",
    "proportion_correct = 0.0\n",
    "num_examples = len(ds[\"test\"])\n",
    "\n",
    "for example in ds[\"test\"]:\n",
    "    prompt = example[\"prompt\"]\n",
    "    completion = example[\"completion\"]\n",
    "    result = check_spelling(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        actual_spelling=completion,\n",
    "        max_new_tokens=20,\n",
    "    )\n",
    "    proportion_correct += result\n",
    "\n",
    "print(f\"{proportion_correct}/{num_examples}.0 words correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ba61",
   "metadata": {},
   "source": [
    "It looks like it has improved! Perhaps with a larger dataset and more training, it could get even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16c690",
   "metadata": {},
   "source": [
    "## Congratulations for completing the exercise! 🎉\n",
    "\n",
    "✅ You did it! You successfully fine-tuned a small language model using PEFT with LoRA to teach it a new skill: spelling! You saw how the base model failed completely at the task, and with a very small amount of data and a short training run, the model started to learn how to spell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f093a0b",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
